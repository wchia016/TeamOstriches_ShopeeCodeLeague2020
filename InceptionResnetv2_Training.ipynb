{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "InceptionResnetv2 Training",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "j06pz3I2MGws",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "29e14a3f-cfb7-4f3a-ba8a-3c51777376aa"
      },
      "source": [
        "'''\n",
        "This notebook covers how to use tf.keras to build a classification model like what we talked about in the previous series.\n",
        "'''"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic": {
              "type": "string"
            },
            "text/plain": [
              "'\\nThis notebook covers how to use tf.keras to build a classification model like what we talked about in the previous series.\\n'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XtLJPANH4-vP",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "78e0c887-68c3-44ae-82af-4225eebca476"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FbcPzAQAwIIi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import os\n",
        "from tqdm import tqdm\n",
        "import pickle\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "\n",
        "tf.keras.backend.clear_session()  # For easy reset of notebook state.\n",
        "\n",
        "# CHANGE THESE TO FIT YOUR FOLDER NAMES\n",
        "full_folder = '/content/gdrive/My Drive/Shopee W2-4 Dataset/'\n",
        "data_folder = os.path.join( full_folder, 'train_1' )\n",
        "test_folder = os.path.join(full_folder, 'test')\n",
        "save_model_folder = os.path.join( full_folder, 'models' )\n",
        "results_folder = os.path.join(full_folder, 'results')\n",
        "\n",
        "input_shape = (224,224,3)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7tcEIvrxKM75",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model_context = 'model_loose_c'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sqja549cjgOC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# When include_top=False, we are discarding the 1000 category predictions\n",
        "transfer_model = tf.keras.applications.InceptionResNetV2(input_shape=input_shape, include_top=False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iFOu8EqylZMH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Now let's rig together a new model\n",
        "def transfer_learning_model(input_shape, base_model, model_name='transfer_learning_model', num_cat = 42):\n",
        "  # Freeze the base model\n",
        "  for layer in base_model.layers:\n",
        "    layer.trainable = False\n",
        "  inputs = keras.Input(shape=input_shape)\n",
        "  # First, run the input through the power model. x contains good extracted features.\n",
        "  x = base_model(inputs)\n",
        "  # Notice that the rest below are more or less the same\n",
        "  x = layers.GlobalAveragePooling2D()(x) #2048\n",
        "\n",
        "  x = layers.Dense(1024)(x)\n",
        "  x = layers.BatchNormalization()(x)\n",
        "  x = layers.ReLU()(x)\n",
        "  \n",
        "  #x = layers.Dropout(0.1)(x)\n",
        "  x = layers.Dense(num_cat)(x)\n",
        "  predictions = layers.Softmax()(x) # predictions = layers.Sigmoid()(x)\n",
        "\n",
        "  model = keras.Model(inputs, predictions, name=model_name)\n",
        "  # Fine tuning requires a lower learning rate. The pre-trained model will be upset by the new rookie layers otherwise.\n",
        "  model.compile( optimizer=tf.keras.optimizers.Adam(0.001),\n",
        "                 loss=keras.losses.CategoricalCrossentropy(from_logits=False),\n",
        "                 metrics=['accuracy'] )\n",
        "  return model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HnHyoHj8mYiE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "transfer_learning_model = transfer_learning_model(input_shape, transfer_model, model_name = model_context, num_cat = 42)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ABAK24COUd1E",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        },
        "outputId": "79af0ea0-18ec-40ad-d646-f343bb8fc4d5"
      },
      "source": [
        "# Set up the data generators to read from our data_folder\n",
        "bs = 80 # The batch size is 32\n",
        "\n",
        "# An object that applies transformations to the images before they are consumed by the model\n",
        "# These transformations include (1) preprocessing, like rescaling or normalization (2) data augmentation\n",
        "datagen = tf.keras.preprocessing.image.ImageDataGenerator(\n",
        "        rescale=1./255, # divide each pixel value by 255. Each pixel is in the range 0-255, so after division it is in 0-1\n",
        "        rotation_range=20, # rotate the image between -20 to +20 degrees\n",
        "        width_shift_range=0.2, # translate the image left-right for 20% of the image's width\n",
        "        height_shift_range=0.2, # same, for up-down and height\n",
        "        zoom_range=0.2,\n",
        "        horizontal_flip=True,\n",
        "        validation_split=0.2)\n",
        "print('Making training data generator...')\n",
        "train_gen = datagen.flow_from_directory(\n",
        "        data_folder,\n",
        "        target_size=input_shape[:2],\n",
        "        batch_size=bs,\n",
        "        subset='training')\n",
        "print('Making validation data generator...')\n",
        "val_gen = datagen.flow_from_directory(\n",
        "        data_folder,\n",
        "        target_size=input_shape[:2],\n",
        "        batch_size=bs,\n",
        "        subset='validation')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Making training data generator...\n",
            "Found 20241 images belonging to 42 classes.\n",
            "Making validation data generator...\n",
            "Found 5037 images belonging to 42 classes.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AfDbGwdUAK19",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 731
        },
        "outputId": "9529f83d-f64f-40ad-a77d-7d819954602a"
      },
      "source": [
        "train_gen.class_indices"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'00': 0,\n",
              " '01': 1,\n",
              " '02': 2,\n",
              " '03': 3,\n",
              " '04': 4,\n",
              " '05': 5,\n",
              " '06': 6,\n",
              " '07': 7,\n",
              " '08': 8,\n",
              " '09': 9,\n",
              " '10': 10,\n",
              " '11': 11,\n",
              " '12': 12,\n",
              " '13': 13,\n",
              " '14': 14,\n",
              " '15': 15,\n",
              " '16': 16,\n",
              " '17': 17,\n",
              " '18': 18,\n",
              " '19': 19,\n",
              " '20': 20,\n",
              " '21': 21,\n",
              " '22': 22,\n",
              " '23': 23,\n",
              " '24': 24,\n",
              " '25': 25,\n",
              " '26': 26,\n",
              " '27': 27,\n",
              " '28': 28,\n",
              " '29': 29,\n",
              " '30': 30,\n",
              " '31': 31,\n",
              " '32': 32,\n",
              " '33': 33,\n",
              " '34': 34,\n",
              " '35': 35,\n",
              " '36': 36,\n",
              " '37': 37,\n",
              " '38': 38,\n",
              " '39': 39,\n",
              " '40': 40,\n",
              " '41': 41}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 38
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QcEmV7yMeEIq",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 731
        },
        "outputId": "bb7e67eb-3051-4a33-9f9b-3f45e5fc389c"
      },
      "source": [
        "# Construct a reverse mapping\n",
        "label_map = {v:k for k,v in train_gen.class_indices.items()}\n",
        "label_map"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{0: '00',\n",
              " 1: '01',\n",
              " 2: '02',\n",
              " 3: '03',\n",
              " 4: '04',\n",
              " 5: '05',\n",
              " 6: '06',\n",
              " 7: '07',\n",
              " 8: '08',\n",
              " 9: '09',\n",
              " 10: '10',\n",
              " 11: '11',\n",
              " 12: '12',\n",
              " 13: '13',\n",
              " 14: '14',\n",
              " 15: '15',\n",
              " 16: '16',\n",
              " 17: '17',\n",
              " 18: '18',\n",
              " 19: '19',\n",
              " 20: '20',\n",
              " 21: '21',\n",
              " 22: '22',\n",
              " 23: '23',\n",
              " 24: '24',\n",
              " 25: '25',\n",
              " 26: '26',\n",
              " 27: '27',\n",
              " 28: '28',\n",
              " 29: '29',\n",
              " 30: '30',\n",
              " 31: '31',\n",
              " 32: '32',\n",
              " 33: '33',\n",
              " 34: '34',\n",
              " 35: '35',\n",
              " 36: '36',\n",
              " 37: '37',\n",
              " 38: '38',\n",
              " 39: '39',\n",
              " 40: '40',\n",
              " 41: '41'}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 39
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dhXkymr7kftG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Notice that we are left with a 7x7 square of depth 2048.\n",
        "# We will apply GAP to reduce this tensor to a vector of length 2048, and train a classifier at the end to distinguish between two classes\n",
        "# But first, we should disable training for the ResNet50 temporarily:\n",
        "for layer in transfer_model.layers:\n",
        "  layer.trainable = False"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CLMi72Pzm6ty",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Use the same callbacks, but with a different model_context\n",
        "model_checkpoint = tf.keras.callbacks.ModelCheckpoint(\n",
        "    filepath=os.path.join( save_model_folder, '{}-best_val_loss.h5'.format(model_context) ),\n",
        "    save_weights_only=False,\n",
        "    monitor='val_loss',\n",
        "    mode='auto',\n",
        "    save_best_only=True)\n",
        "\n",
        "# If the validation loss doesn't improve for 20 epochs, stop training\n",
        "earlystopping = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=20)\n",
        "\n",
        "# If the validation loss doesn't improve for 5 epochs, reduce the learning rate to 0.2 times it's previous value\n",
        "reduce_lr = tf.keras.callbacks.ReduceLROnPlateau(monitor='val_loss', factor=0.2, patience=5)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NbcV0PnZp_c7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Load checkpoint cell\n",
        "#load_model_path = os.path.join(save_model_folder, 'model_loose_c-best_val_loss.h5')\n",
        "#transfer_learning_model = tf.keras.models.load_model(load_model_path)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JsuMzHhmnEl0",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 986
        },
        "outputId": "d2eb6a9b-419b-4752-9b27-401c5801e4ce"
      },
      "source": [
        "# Warm up for 10 epochs\n",
        "n_epochs_warmup=5\n",
        "# Followed by 40 epochs with all params trainable\n",
        "n_epochs_fullblast=30\n",
        "\n",
        "print('Warming up for {} epochs...'.format(n_epochs_warmup))\n",
        "history_warmup = transfer_learning_model.fit(train_gen,\n",
        "          epochs=n_epochs_warmup,\n",
        "          steps_per_epoch=train_gen.n // bs,\n",
        "          validation_data=val_gen,\n",
        "          validation_steps=val_gen.n // bs,\n",
        "          callbacks=[model_checkpoint, earlystopping, reduce_lr])\n",
        "\n",
        "load_model_path = os.path.join(save_model_folder, '{}-best_val_loss.h5'.format(model_context) )\n",
        "del transfer_learning_model\n",
        "transfer_learning_model = tf.keras.models.load_model(load_model_path)\n",
        "\n",
        "\n",
        "print('Done. Unfreezing all layers and training for {} more epochs...'.format(n_epochs_fullblast))\n",
        "# After the warm-up, unfreeze all the layers of the base ResNet50\n",
        "for layer in transfer_learning_model.get_layer('inception_resnet_v2').layers:\n",
        "  layer.trainable = True\n",
        "\n",
        "history_fullblast = transfer_learning_model.fit(train_gen,\n",
        "          epochs=n_epochs_fullblast,\n",
        "          steps_per_epoch=train_gen.n // bs,\n",
        "          validation_data=val_gen,\n",
        "          validation_steps=val_gen.n // bs,\n",
        "          callbacks=[model_checkpoint, earlystopping, reduce_lr])\n",
        "\n",
        "load_model_path = os.path.join(save_model_folder, '{}-best_val_loss.h5'.format(model_context) )\n",
        "del transfer_learning_model\n",
        "transfer_learning_model = tf.keras.models.load_model(load_model_path)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Warming up for 5 epochs...\n",
            "Epoch 1/5\n",
            "252/252 [==============================] - 12695s 50s/step - loss: 1.1292 - accuracy: 0.6938 - val_loss: 1.0301 - val_accuracy: 0.7121 - lr: 8.0000e-06\n",
            "Epoch 2/5\n",
            "252/252 [==============================] - 625s 2s/step - loss: 1.1272 - accuracy: 0.6918 - val_loss: 1.0272 - val_accuracy: 0.7143 - lr: 8.0000e-06\n",
            "Epoch 3/5\n",
            "252/252 [==============================] - 609s 2s/step - loss: 1.1232 - accuracy: 0.6902 - val_loss: 1.0123 - val_accuracy: 0.7097 - lr: 8.0000e-06\n",
            "Epoch 4/5\n",
            "252/252 [==============================] - 604s 2s/step - loss: 1.1147 - accuracy: 0.6925 - val_loss: 1.0353 - val_accuracy: 0.7042 - lr: 8.0000e-06\n",
            "Epoch 5/5\n",
            "252/252 [==============================] - 607s 2s/step - loss: 1.0959 - accuracy: 0.6963 - val_loss: 1.0106 - val_accuracy: 0.7105 - lr: 8.0000e-06\n",
            "Done. Unfreezing all layers and training for 30 more epochs...\n",
            "Epoch 1/30\n",
            "252/252 [==============================] - 602s 2s/step - loss: 1.1139 - accuracy: 0.6944 - val_loss: 1.0279 - val_accuracy: 0.7175 - lr: 8.0000e-06\n",
            "Epoch 2/30\n",
            "252/252 [==============================] - 599s 2s/step - loss: 1.0972 - accuracy: 0.6966 - val_loss: 1.0059 - val_accuracy: 0.7188 - lr: 8.0000e-06\n",
            "Epoch 3/30\n",
            "252/252 [==============================] - 594s 2s/step - loss: 1.0946 - accuracy: 0.6980 - val_loss: 1.0177 - val_accuracy: 0.7153 - lr: 8.0000e-06\n",
            "Epoch 4/30\n",
            "252/252 [==============================] - 596s 2s/step - loss: 1.0859 - accuracy: 0.6997 - val_loss: 1.0188 - val_accuracy: 0.7083 - lr: 8.0000e-06\n",
            "Epoch 5/30\n",
            "252/252 [==============================] - 594s 2s/step - loss: 1.0778 - accuracy: 0.7009 - val_loss: 1.0348 - val_accuracy: 0.7079 - lr: 8.0000e-06\n",
            "Epoch 6/30\n",
            "252/252 [==============================] - 595s 2s/step - loss: 1.0763 - accuracy: 0.6992 - val_loss: 1.0258 - val_accuracy: 0.7101 - lr: 8.0000e-06\n",
            "Epoch 7/30\n",
            "252/252 [==============================] - 598s 2s/step - loss: 1.0689 - accuracy: 0.7043 - val_loss: 1.0137 - val_accuracy: 0.7133 - lr: 8.0000e-06\n",
            "Epoch 8/30\n",
            "252/252 [==============================] - 597s 2s/step - loss: 1.0628 - accuracy: 0.7011 - val_loss: 1.0188 - val_accuracy: 0.7139 - lr: 1.6000e-06\n",
            "Epoch 9/30\n",
            "252/252 [==============================] - 596s 2s/step - loss: 1.0564 - accuracy: 0.7047 - val_loss: 1.0152 - val_accuracy: 0.7202 - lr: 1.6000e-06\n",
            "Epoch 10/30\n",
            "252/252 [==============================] - 596s 2s/step - loss: 1.0713 - accuracy: 0.7015 - val_loss: 1.0242 - val_accuracy: 0.7069 - lr: 1.6000e-06\n",
            "Epoch 11/30\n",
            "252/252 [==============================] - 596s 2s/step - loss: 1.0678 - accuracy: 0.7004 - val_loss: 1.0277 - val_accuracy: 0.7089 - lr: 1.6000e-06\n",
            "Epoch 12/30\n",
            " 30/252 [==>...........................] - ETA: 6:46 - loss: 1.0956 - accuracy: 0.6979"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-28-0fbe2e65b455>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     27\u001b[0m           \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mval_gen\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m           \u001b[0mvalidation_steps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mval_gen\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn\u001b[0m \u001b[0;34m//\u001b[0m \u001b[0mbs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 29\u001b[0;31m           callbacks=[model_checkpoint, earlystopping, reduce_lr])\n\u001b[0m\u001b[1;32m     30\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m \u001b[0mload_model_path\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msave_model_folder\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'{}-best_val_loss.h5'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_context\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36m_method_wrapper\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m     64\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_method_wrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_in_multi_worker_mode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 66\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     67\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     68\u001b[0m     \u001b[0;31m# Running inside `run_distribute_coordinator` already.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m    846\u001b[0m                 batch_size=batch_size):\n\u001b[1;32m    847\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 848\u001b[0;31m               \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    849\u001b[0m               \u001b[0;31m# Catch OutOfRangeError for Datasets of unknown size.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    850\u001b[0m               \u001b[0;31m# This blocks until the batch has finished executing.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    578\u001b[0m         \u001b[0mxla_context\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mExit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    579\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 580\u001b[0;31m       \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    581\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    582\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mtracing_count\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    609\u001b[0m       \u001b[0;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    610\u001b[0m       \u001b[0;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 611\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=not-callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    612\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    613\u001b[0m       \u001b[0;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2418\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2419\u001b[0m       \u001b[0mgraph_function\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_define_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2420\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_filtered_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2421\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2422\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_filtered_call\u001b[0;34m(self, args, kwargs)\u001b[0m\n\u001b[1;32m   1663\u001b[0m          if isinstance(t, (ops.Tensor,\n\u001b[1;32m   1664\u001b[0m                            resource_variable_ops.BaseResourceVariable))),\n\u001b[0;32m-> 1665\u001b[0;31m         self.captured_inputs)\n\u001b[0m\u001b[1;32m   1666\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1667\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_call_flat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcaptured_inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcancellation_manager\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1744\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1745\u001b[0m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0;32m-> 1746\u001b[0;31m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0m\u001b[1;32m   1747\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[1;32m   1748\u001b[0m         \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    596\u001b[0m               \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    597\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattrs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 598\u001b[0;31m               ctx=ctx)\n\u001b[0m\u001b[1;32m    599\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    600\u001b[0m           outputs = execute.execute_with_cancellation(\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     58\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0;32m---> 60\u001b[0;31m                                         inputs, attrs, num_outputs)\n\u001b[0m\u001b[1;32m     61\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cNDYODixV0JD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from tensorflow.keras.preprocessing.image import load_img, img_to_array\n",
        "\n",
        "def run_image_on_model(img_path, model, label_map):\n",
        "  pil_img = load_img(test_img_path)\n",
        "  pil_img = pil_img.resize( input_shape[:2] )\n",
        "  img_arr = img_to_array(pil_img)\n",
        "  # Remember to normalize the image values the same way you did when you trained the model\n",
        "  img_arr = img_arr / 255.\n",
        "  # We need to wrap this in an np.array with dimensions (b,H,W,C). Currently, the shape is only (H,W,C)\n",
        "  img_arr = np.array( [img_arr] )\n",
        "  pred = model.predict(img_arr, batch_size=1)[0]\n",
        "  pred_idx = np.argmax(pred)\n",
        "  return label_map[pred_idx]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lihLvAa-Cp-M",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "6aa6dd1e-0d1a-43ce-cb8e-b0a4fe4e8e1b"
      },
      "source": [
        "test_df = pd.read_csv(\"/content/gdrive/My Drive/Shopee W2-4 Dataset/test.csv\")\n",
        "\n",
        "for i in tqdm(range(len(test_df.index))):\n",
        "  test_img_path = os.path.join(test_folder, test_df.iloc[i]['filename'])\n",
        "  predicted_category = run_image_on_model(test_img_path, transfer_learning_model, label_map)\n",
        "  test_df.at[i, 'category'] = predicted_category\n",
        "test_df[\"category\"] = test_df[\"category\"].apply(lambda x: \"{:02}\".format(x)) \n",
        "csv_path = os.path.join(results_folder, \"test_{}.csv\".format(model_context))\n",
        "test_df.to_csv(csv_path, index = False)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 12186/12186 [21:35<00:00,  9.41it/s]\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Rag9QGKOlRzf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}